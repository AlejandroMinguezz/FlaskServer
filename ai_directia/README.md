# DirectIA - Sistema de Clasificaci√≥n IA de Documentos

Sistema de clasificaci√≥n autom√°tica de documentos administrativos usando Machine Learning.

## üìã √çndice

- [Estructura del Proyecto](#estructura-del-proyecto)
- [Instalaci√≥n](#instalaci√≥n)
- [Gu√≠a de Uso R√°pida](#gu√≠a-de-uso-r√°pida)
- [Categor√≠as de Documentos](#categor√≠as-de-documentos)
- [Pipeline de Clasificaci√≥n](#pipeline-de-clasificaci√≥n)
- [Integraci√≥n con Backend](#integraci√≥n-con-backend)
- [Testing y Debugging](#testing-y-debugging)
- [M√©tricas y Rendimiento](#m√©tricas-y-rendimiento)

## Estructura del Proyecto

```
ai/
‚îú‚îÄ‚îÄ datasets/              # Datasets para entrenamiento
‚îÇ   ‚îú‚îÄ‚îÄ raw/              # Documentos originales por categor√≠a
‚îÇ   ‚îú‚îÄ‚îÄ processed/        # Datos procesados (train/val/test CSV)
‚îÇ   ‚îî‚îÄ‚îÄ synthetic/        # Datos sint√©ticos generados
‚îú‚îÄ‚îÄ models/               # Modelos entrenados y vectorizadores
‚îÇ   ‚îî‚îÄ‚îÄ v1_tfidf_svm/    # Modelo v1 (TF-IDF + SVM)
‚îÇ       ‚îú‚îÄ‚îÄ model.pkl
‚îÇ       ‚îú‚îÄ‚îÄ vectorizer.pkl
‚îÇ       ‚îî‚îÄ‚îÄ metadata.json
‚îú‚îÄ‚îÄ extractors/           # Extracci√≥n de texto (PDF, DOCX, TXT, OCR)
‚îÇ   ‚îú‚îÄ‚îÄ pdf_extractor.py
‚îÇ   ‚îú‚îÄ‚îÄ docx_extractor.py
‚îÇ   ‚îú‚îÄ‚îÄ txt_extractor.py
‚îÇ   ‚îú‚îÄ‚îÄ ocr_extractor.py
‚îÇ   ‚îî‚îÄ‚îÄ unified_extractor.py
‚îú‚îÄ‚îÄ preprocessing/        # Pipeline de preprocesamiento
‚îÇ   ‚îú‚îÄ‚îÄ text_cleaner.py
‚îÇ   ‚îî‚îÄ‚îÄ feature_extractor.py
‚îú‚îÄ‚îÄ training/            # Scripts de entrenamiento
‚îÇ   ‚îî‚îÄ‚îÄ train_model.py
‚îú‚îÄ‚îÄ inference/           # Clasificaci√≥n en tiempo real
‚îÇ   ‚îî‚îÄ‚îÄ classifier.py
‚îú‚îÄ‚îÄ data_generation/     # Generaci√≥n de datos sint√©ticos
‚îÇ   ‚îú‚îÄ‚îÄ template_generator.py
‚îÇ   ‚îú‚îÄ‚îÄ augmentation.py
‚îÇ   ‚îî‚îÄ‚îÄ generate_dataset.py
‚îú‚îÄ‚îÄ config/              # Configuraci√≥n y categor√≠as
‚îÇ   ‚îî‚îÄ‚îÄ categories.json
‚îú‚îÄ‚îÄ requirements_ai.txt  # Dependencias del sistema IA
‚îú‚îÄ‚îÄ test_classifier.py   # Script de pruebas
‚îú‚îÄ‚îÄ BACKEND_INTEGRATION.md  # Gu√≠a de integraci√≥n
‚îî‚îÄ‚îÄ README.md           # Este archivo
```

## Instalaci√≥n

### 1. Instalar Dependencias Python

```bash
pip install -r ai/requirements_ai.txt
```

### 2. Descargar Recursos de NLP

```bash
# Stopwords de NLTK (opcional pero recomendado)
python -c "import nltk; nltk.download('stopwords'); nltk.download('punkt')"
```

### 3. Instalar Tesseract OCR (para reconocimiento de im√°genes)

**Windows:**
- Descargar desde: https://github.com/UB-Mannheim/tesseract/wiki
- Instalar y agregar al PATH

**Linux:**
```bash
sudo apt-get install tesseract-ocr tesseract-ocr-spa
```

**macOS:**
```bash
brew install tesseract tesseract-lang
```

## Gu√≠a de Uso R√°pida

### Paso 1: Generar Dataset Sint√©tico

```bash
# Generar 100 documentos por categor√≠a (+ 3 variaciones = 400 por categor√≠a)
python -m ai.data_generation.generate_dataset --num-docs 100 --num-variations 3

# Resultado: ~3,600 documentos en total (9 categor√≠as √ó 400 docs)
# Guardados en: ai/datasets/processed/ (train.csv, val.csv, test.csv)
```

**Opciones adicionales:**
```bash
# Generar m√°s documentos para mejor precisi√≥n
python -m ai.data_generation.generate_dataset --num-docs 200

# No guardar archivos TXT individuales (m√°s r√°pido)
python -m ai.data_generation.generate_dataset --no-txt

# Ajustar proporciones del split
python -m ai.data_generation.generate_dataset --train-ratio 0.8 --val-ratio 0.1 --test-ratio 0.1
```

### Paso 2: Entrenar el Modelo

```bash
# Entrenar modelo SVM (recomendado)
python -m ai.training.train_model

# Opciones avanzadas:
python -m ai.training.train_model \
  --model-type svm \
  --max-features 5000 \
  --svm-kernel linear \
  --svm-c 1.0 \
  --output-dir ai/models/v1_tfidf_svm
```

**Modelos disponibles:**
- `svm`: Support Vector Machine (mejor precisi√≥n, recomendado)
- `naive_bayes`: Naive Bayes (m√°s r√°pido, menor precisi√≥n)
- `random_forest`: Random Forest (balance entre velocidad y precisi√≥n)

### Paso 3: Usar el Clasificador

#### Desde Python:

```python
from ai.inference.classifier import DocumentClassifier

# Inicializar clasificador
classifier = DocumentClassifier(
    model_dir='ai/models/v1_tfidf_svm',
    config_path='ai/config/categories.json'
)

# Clasificar archivo
result = classifier.classify_file('ruta/a/documento.pdf')

print(f"Tipo: {result['tipo_documento']}")
print(f"Confianza: {result['confianza']:.2%}")
print(f"Carpeta sugerida: {result['carpeta_sugerida']}")

# Clasificar desde bytes (√∫til para APIs)
with open('documento.pdf', 'rb') as f:
    file_bytes = f.read()

result = classifier.classify_file_bytes(file_bytes, 'pdf', 'documento.pdf')
```

#### Desde l√≠nea de comandos:

```bash
# Clasificar un archivo
python ai/test_classifier.py --file ruta/a/documento.pdf

# Clasificar texto directo
python ai/test_classifier.py --text "FACTURA N.¬∫ 1234..."

# Probar con documentos sint√©ticos
python ai/test_classifier.py --test-synthetic

# Ver categor√≠as disponibles
python ai/test_classifier.py --show-categories

# Ver informaci√≥n del modelo
python ai/test_classifier.py --show-info
```

## Categor√≠as de Documentos

El sistema clasifica documentos en 9 categor√≠as:

| ID | Nombre | Carpeta | Palabras Clave |
|----|--------|---------|----------------|
| `factura` | Factura | `/Documentos/Facturas/` | factura, invoice, IVA, total, importe, CIF |
| `contrato` | Contrato | `/Documentos/Contratos/` | contrato, cl√°usula, firmante, vigencia |
| `nomina` | N√≥mina | `/Documentos/N√≥minas/` | n√≥mina, salario, IRPF, seguridad social |
| `presupuesto` | Presupuesto | `/Documentos/Presupuestos/` | presupuesto, cotizaci√≥n, validez, oferta |
| `recibo` | Recibo | `/Documentos/Recibos/` | recibo, pago, consumo, alquiler |
| `certificado` | Certificado | `/Documentos/Certificados/` | certificado, acredita, expedido por |
| `fiscal` | Declaraci√≥n Fiscal | `/Documentos/Fiscales/` | declaraci√≥n, modelo, renta, hacienda |
| `notificacion` | Notificaci√≥n Admin | `/Documentos/Notificaciones/` | notificaci√≥n, administraci√≥n, expediente |
| `otro` | Otro | `/Documentos/Otros/` | (catch-all para documentos no clasificables) |

## Pipeline de Clasificaci√≥n

```
Documento (PDF/DOCX/TXT/IMG)
         ‚Üì
[1. EXTRACCI√ìN DE TEXTO]
  - PDF: pdfplumber
  - DOCX: python-docx
  - TXT: lectura directa
  - IMG: Tesseract OCR
         ‚Üì
      Texto plano
         ‚Üì
[2. PREPROCESAMIENTO]
  - Normalizaci√≥n Unicode
  - Limpieza de espacios
  - Eliminaci√≥n de URLs/emails
  - Tokenizaci√≥n
  - Eliminaci√≥n de stopwords
         ‚Üì
  Texto preprocesado
         ‚Üì
[3. EXTRACCI√ìN DE FEATURES]
  - Vectorizaci√≥n TF-IDF
  - Max features: 5000
  - N-grams: (1, 2)
         ‚Üì
   Vector de caracter√≠sticas
         ‚Üì
[4. CLASIFICACI√ìN]
  - Modelo SVM entrenado
  - Predicci√≥n + probabilidades
         ‚Üì
[5. POST-PROCESAMIENTO]
  - Mapeo a categor√≠a
  - Generaci√≥n de carpeta sugerida
  - Determinaci√≥n de nivel de confianza
         ‚Üì
Resultado JSON con predicci√≥n
```

## Integraci√≥n con Backend

Ver documentaci√≥n completa en: [BACKEND_INTEGRATION.md](ai/BACKEND_INTEGRATION.md:1)

### Resumen R√°pido

```python
# En tu aplicaci√≥n Flask
from ai.inference.classifier import DocumentClassifier

classifier = DocumentClassifier()

@app.route('/api/clasificar', methods=['POST'])
def clasificar_documento():
    file = request.files['file']
    file_bytes = file.read()
    file_extension = os.path.splitext(file.filename)[1].lstrip('.')

    result = classifier.classify_file_bytes(
        file_bytes=file_bytes,
        file_extension=file_extension,
        file_name=file.filename
    )

    return jsonify(result), 200
```

## Testing y Debugging

### Probar el Sistema Completo

```bash
# 1. Generar datos
python -m ai.data_generation.generate_dataset --num-docs 50

# 2. Entrenar modelo
python -m ai.training.train_model

# 3. Probar con documentos sint√©ticos
python ai/test_classifier.py --test-synthetic

# 4. Ver informaci√≥n del modelo
python ai/test_classifier.py --show-info
```

### Verificar Extracci√≥n de Texto

```python
from ai.extractors import extract_text

result = extract_text('documento.pdf')
print(f"√âxito: {result['success']}")
print(f"Texto extra√≠do: {result['text'][:500]}")
print(f"Error: {result.get('error', 'N/A')}")
```

### Verificar Preprocesamiento

```python
from ai.preprocessing import preprocess_text

text = "FACTURA N.¬∫ 1234, TOTAL: 1,500.00‚Ç¨"
processed = preprocess_text(text)
print(f"Original: {text}")
print(f"Procesado: {processed}")
```

## M√©tricas y Rendimiento

### Objetivos de Rendimiento

| M√©trica | Objetivo | Descripci√≥n |
|---------|----------|-------------|
| **Accuracy** | > 85% | Porcentaje de predicciones correctas |
| **F1-Score (macro)** | > 0.80 | Balance entre precisi√≥n y recall |
| **Tiempo de inferencia** | < 2s | Tiempo para clasificar un documento |
| **Formatos soportados** | PDF, DOCX, TXT, IMG | Tipos de documentos procesables |

### Ver M√©tricas del Modelo

```bash
# Ver m√©tricas desde CLI
python ai/test_classifier.py --show-info

# O desde Python:
from ai.inference.classifier import DocumentClassifier
classifier = DocumentClassifier()
info = classifier.get_model_info()
print(f"Accuracy: {info['metrics']['test']['accuracy']:.2%}")
print(f"F1-Score: {info['metrics']['test']['f1_macro']:.2%}")
```

### Mejorar el Rendimiento

Si la precisi√≥n es baja:

1. **Generar m√°s datos:**
   ```bash
   python -m ai.data_generation.generate_dataset --num-docs 200 --num-variations 5
   ```

2. **Ajustar hiperpar√°metros:**
   ```bash
   python -m ai.training.train_model --max-features 10000 --svm-c 2.0
   ```

3. **Probar otros modelos:**
   ```bash
   python -m ai.training.train_model --model-type random_forest
   ```

4. **Reentrenar con documentos reales** (si est√°n disponibles)

## Troubleshooting

### Error: "Model not found"

```bash
# Soluci√≥n: Entrenar el modelo
python -m ai.training.train_model
```

### Error: "Tesseract not found"

```bash
# Windows: Instalar Tesseract y agregar al PATH
# Linux: sudo apt-get install tesseract-ocr tesseract-ocr-spa
# macOS: brew install tesseract tesseract-lang
```

### Baja precisi√≥n en clasificaci√≥n

1. Generar m√°s datos sint√©ticos
2. Ajustar hiperpar√°metros del modelo
3. Verificar que las palabras clave en `config/categories.json` sean representativas
4. Considerar reentrenar con documentos reales

### Lentitud en clasificaci√≥n

1. Usar modelo m√°s ligero: `--model-type naive_bayes`
2. Reducir features: `--max-features 3000`
3. Implementar cach√© para documentos repetidos

## Pr√≥ximos Pasos

- [ ] Implementar feedback del usuario para mejorar el modelo
- [ ] Agregar soporte para m√°s tipos de documentos
- [ ] Implementar modelo v2 con BERT fine-tuned
- [ ] Agregar clasificaci√≥n multiidioma
- [ ] Implementar extracci√≥n de entidades (fechas, importes, nombres)
- [ ] Agregar detecci√≥n de duplicados
- [ ] Implementar b√∫squeda sem√°ntica

## Versi√≥n

- **v1.0** (actual): ML tradicional (TF-IDF + SVM)
- **v2.0** (futuro): Deep Learning (BERT fine-tuned para espa√±ol)
